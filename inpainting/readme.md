<b> InPainting workflows 


In researching InPainting using SDXL 1.0 in ComfyUI I've come across three different methods that seem to be commonly used: Base Model with Latent Noise Mask, Base Model using InPaint VAE Encode and using the UNET "diffusion_pytorch" InPaint specific model from Hugging Face. So in this workflow each of them will run on your input image and you can select the one that produces the best results. You can also turn each process on/off for each run. Instructions and listing of necessary Resources are in Note files.



